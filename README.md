# Dakoda-Core

# DAKODA Corpus Processing & Analysis

This repository contains example notebooks and code to process, browse, and compare learner corpora metadata for the DAKODA project.

---

## General Setup

### Requirements

- Python 3.7 or higher
- pandas
- polars
- lxml (for XML parsing)
- ipywidgets (for interactive widgets)
- plotly (for interactive visualizations)
- itables (for interactive tables in notebooks)
- matplotlib
- seaborn

You can install all required packages with:

```sh
pip install pandas polars lxml ipywidgets plotly itables matplotlib seaborn
```


# Corpus Processing (Corpus_Processing_Pandas_Polars.ipynb)

## Overview

This notebook demonstrates how to process learner corpora data stored in XMI files for the DAKODA project.

We show how to:

- Read and parse XMI files to extract basic statistics like document length, token count, sentence count, and annotation count.
- Use both Pandas and Polars libraries for processing data as DataFrames.
- Save the extracted information as CSV files for further use.

## Instructions

1. **Set your data paths:**

Replace the dummy paths in the notebook (`cdlk_path` and `klp1_path`) with the actual paths to your corpus folders containing XMI files.

2. **Run the notebook cells:**

The notebook will process the files and display sample data for each corpus and backend.

3. **Output files:**

The processed data will be saved as CSV files (`xmi_basic_info_cdlk_pandas.csv`, `xmi_basic_info_klp1_pandas.csv`, etc.) in the notebook directory.

These CSVs can be used for further analysis or shared.

## Requirements

- Python 3.7+
- pandas
- polars
- lxml (for XML parsing)
- ipywidgets (for interactive widgets, future notebooks)

Install requirements using:

```sh
pip install pandas polars lxml ipywidgets
```


# Interactive Corpus Browser (Corpus_Browser.ipynb)

## Overview

This notebook provides an interactive interface to browse and visualize corpus metadata summaries.

- Users can select which corpus to load (CDLK or KLP1).
- Choose the data processing backend (Pandas or Polars).
- Preview the first 10 rows interactively with sorting and paging.
- View basic descriptive statistics.
- Visualize distributions of document lengths, token counts, and sentence counts with interactive Plotly histograms.

## Setup

1. Ensure the CSV summary files `xmi_basic_info_cdlk.csv` and `xmi_basic_info_klp1.csv` exist in the notebook directory. These are generated by the corpus processing notebook (Task 1).

2. Install dependencies if needed:

```sh
pip install pandas polars ipywidgets plotly itables
```


# Corpus Comparison (corpus_comparison.ipynb)

## Overview

This notebook compares the two corpora, CDLK and KLP1, based on the preprocessed metadata extracted earlier.

- Loads corpus metadata CSVs into pandas DataFrames.
- Adds labels to distinguish corpora.
- Combines datasets for unified analysis.
- Computes summary statistics such as mean, median, standard deviation, min, and max for document lengths, token counts, and sentence counts.
- Visualizes the distributions with side-by-side boxplots for easy comparison.

## Usage

- Make sure CSV summary files `xmi_basic_info_cdlk.csv` and `xmi_basic_info_klp1.csv` are available.
- Run all cells to view summary stats and plots.
- No coding experience required; the notebook includes detailed comments for guidance.

## Purpose

This comparison helps identify differences in corpus size and structure, useful for further linguistic analysis or preprocessing decisions.


# Notes
- Paths inside notebooks use dummy placeholders â€” update these with your actual data paths before running.
- Notebooks are designed to be simple and clear for non-technical users.
- For advanced usage, notebooks demonstrate both Pandas and Polars usage side-by-side for flexible workflow choices.

# About plots visibility in notebooks:
Plots generated with matplotlib, seaborn, and plotly will be saved within the notebook outputs when you run and save your notebook. When you share the notebook (.ipynb), the recipients will be able to see the plots as rendered outputs directly, provided they open the notebook in a compatible viewer like Jupyter Notebook, JupyterLab, or VSCode.

